# Kiro Gateway - Environment Configuration
# Copy this file to .env and fill in your values

# ------------------------------------------------------------------
# Minimal .env template (safe placeholders)
# ------------------------------------------------------------------
# PROXY_API_KEY=""
# KIRO_CLI_DB_FILE=""
# VPN_PROXY_URL=""
# SERVER_HOST="0.0.0.0"
# SERVER_PORT="8000"
# KIRO_REGION="us-east-1"
# LOG_LEVEL="INFO"
# DEBUG_MODE="off"
# FAKE_REASONING=false
# ALLOW_UNTRUSTED_TLS=false
# THINKING_ANTHROPIC_HIGH_TOKENS=3000
# THINKING_ANTHROPIC_MAX_TOKENS=4000

# ===========================================
# REQUIRED
# ===========================================

# Password to protect YOUR proxy server
# This is NOT a token from anywhere - YOU make it up!
# Use this same value as api_key when connecting to your gateway
# Example: "my-super-secret-password-123" or any secure string
# IMPORTANT: startup fails if this value is left unchanged.
PROXY_API_KEY="my-super-secret-password-123"

# Optional additional keys accepted by the gateway (comma-separated)
# Useful during client key migration
# PROXY_API_KEY_ALIASES="old-key-1,old-key-2"

# ===========================================
# OPTION 1: Kiro IDE credentials (JSON file)
# ===========================================

# Path to JSON credentials file from Kiro IDE
# KIRO_CREDS_FILE="~/.aws/sso/cache/kiro-auth-token.json"

# ===========================================
# OPTION 2: Kiro IDE refresh token
# ===========================================

# Your Kiro refresh token obtained from Kiro IDE traffic.
# REFRESH_TOKEN="your_kiro_refresh_token_here"

# ===========================================
# OPTION 3: kiro-cli SQLite database (AWS SSO)
# ===========================================

# Path to kiro-cli SQLite database (for AWS IAM Identity Center users)
# The gateway will auto-detect AWS SSO OIDC and use the correct endpoint
# KIRO_CLI_DB_FILE="~/.local/share/kiro-cli/data.sqlite3"

# ===========================================
# OPTION 4: AWS SSO cache file (kiro-cli)
# ===========================================

# Path to AWS SSO cache file (contains clientId and clientSecret)
# The gateway will auto-detect AWS SSO OIDC and use the correct endpoint
# KIRO_CREDS_FILE="~/.aws/sso/cache/your-sso-cache-file.json"

# ===========================================
# PROFILE ARN (optional)
# ===========================================

# AWS CodeWhisperer profile ARN
# For Kiro IDE: usually auto-detected from credentials file
# For kiro-cli (AWS SSO / Builder ID): not needed, will be ignored
# PROFILE_ARN="arn:aws:codewhisperer:us-east-1:..."

# ===========================================
# OPTIONAL
# ===========================================

# AWS region (default: us-east-1)
# KIRO_REGION="us-east-1"

# ===========================================
# SERVER SETTINGS
# ===========================================

# Server host (default: 0.0.0.0 - listen on all interfaces)
# Use "127.0.0.1" to only allow local connections
# SERVER_HOST="0.0.0.0"

# Server port (default: 8000)
# Useful when port 8000 is already in use by another application
#
# Configuration priority (highest to lowest):
#   1. CLI arguments: python main.py --port 9000
#   2. Environment variables: SERVER_PORT=9000
#   3. Default value: 8000
#
# Note: When using `uvicorn main:app --port 9000` directly,
# uvicorn handles its own CLI arguments (this setting is ignored)
# SERVER_PORT="8000"

# ===========================================
# VPN/PROXY SETTINGS
# ===========================================

# VPN/Proxy URL for accessing Kiro API through a proxy server.
# Leave empty to connect directly (default).
#
# Use cases:
#   - China: GFW (Great Firewall) blocks AWS endpoints
#   - Corporate networks: Often require mandatory proxy
#   - Privacy: Hide your IP address from AWS
#
# Supports HTTP and SOCKS5 protocols.
# Authentication can be embedded in the URL.
#
# Examples:
#   VPN_PROXY_URL="http://127.0.0.1:7890"
#   VPN_PROXY_URL="socks5://127.0.0.1:1080"
#   VPN_PROXY_URL="http://user:password@proxy.company.com:8080"
#   VPN_PROXY_URL="192.168.1.100:8080"  # defaults to http://
#
# VPN_PROXY_URL=""

# Allow upstream TLS with untrusted certificates (NOT recommended).
# Use only if your proxy does HTTPS MITM and you trust that proxy.
# Default: false (secure TLS verification enabled)
# ALLOW_UNTRUSTED_TLS=false

# ===========================================
# FIRST TOKEN TIMEOUT (Streaming Retry)
# ===========================================

# Timeout for waiting for the first token from the model (in seconds).
# If the model doesn't respond within this time, the request will be cancelled and retried.
# This helps handle "stuck" requests when the model takes too long to start responding.
# Default: 15 seconds (recommended for production)
# Set a lower value (e.g., 5-10) for more aggressive retry behavior.
# FIRST_TOKEN_TIMEOUT="15"

# Maximum number of retry attempts when first token timeout occurs.
# After exhausting all attempts, a 504 Gateway Timeout error will be returned.
# Default: 3 attempts
# FIRST_TOKEN_MAX_RETRIES="3"

# Read timeout for streaming responses (in seconds).
# This is the maximum time to wait for data between chunks during streaming.
# Should be longer than FIRST_TOKEN_TIMEOUT since the model may pause between chunks
# while "thinking" (especially for tool calls or complex reasoning).
# Default: 300 seconds (5 minutes) - generous timeout to avoid premature disconnects.
# STREAMING_READ_TIMEOUT="300"

# ===========================================
# FAKE REASONING (Extended Thinking via Tag Injection)
# ===========================================

# Enable fake reasoning - injects special tags into requests to enable model reasoning.
# When enabled, the model will include its reasoning process in the response.
# The response is then parsed and converted to OpenAI-compatible reasoning_content format.
#
# WHY "FAKE"? This is NOT native extended thinking API support. Instead, we inject
# <thinking_mode>enabled</thinking_mode> tags into the prompt, and the model responds
# with <thinking>...</thinking> blocks that we parse and convert to reasoning_content.
# It works great, but it's a hack - hence "fake" reasoning.
#
# Default: false (disabled unless explicitly enabled)
# Enable explicitly if needed:
# FAKE_REASONING=true

# Maximum thinking length in tokens.
# This value is injected into the request as <max_thinking_length>{value}</max_thinking_length>
# Higher values allow for more detailed reasoning but increase response time and token usage.
# Default: 4000 tokens
# FAKE_REASONING_MAX_TOKENS=4000

# Request-driven thinking policy budgets.
# These are used only when clients explicitly provide reasoning/thinking controls.
# If request has no thinking hints, gateway falls back to FAKE_REASONING_* defaults above.
#
# OpenAI-style levels: off|low|medium|high|xhigh (+ minimal alias)
# THINKING_OPENAI_MINIMAL_TOKENS=600
# THINKING_OPENAI_LOW_TOKENS=600
# THINKING_OPENAI_MEDIUM_TOKENS=1800
# THINKING_OPENAI_HIGH_TOKENS=3000
# THINKING_OPENAI_XHIGH_TOKENS=4000
#
# Anthropic-style levels: off|high|max
# THINKING_ANTHROPIC_HIGH_TOKENS=3000
# THINKING_ANTHROPIC_MAX_TOKENS=4000
#
# Global clamp for explicit numeric budgets from body/headers
# THINKING_MIN_TOKENS=256
# THINKING_MAX_TOKENS=120000

# How to handle the thinking block in responses:
# - "as_reasoning_content": Extract to reasoning_content field (OpenAI-compatible, recommended)
# - "remove": Remove thinking block completely, return only final answer
# - "pass": Pass through as-is with original tags in content
# - "strip_tags": Remove tags but keep thinking content in regular content
#
# Default: "as_reasoning_content"
# FAKE_REASONING_HANDLING=as_reasoning_content

# Maximum size of initial buffer for tag detection (characters).
# The parser buffers this many characters before deciding if response contains thinking tags.
# Lower values = faster first token appearance, but may miss tags with leading whitespace.
# Default: 20 characters (enough for longest tag <reasoning> = 11 chars + some whitespace)
# FAKE_REASONING_INITIAL_BUFFER_SIZE=20

# ===========================================
# TRUNCATION RECOVERY
# ===========================================

# Enable automatic truncation recovery when Kiro API cuts off large responses.
# When the model generates large tool calls or content, the upstream API may truncate
# the response mid-stream. This feature automatically notifies the model about truncation,
# allowing it to adapt its approach (e.g., write smaller files, split operations).
#
# Default: true (ENABLED by default for better out-of-the-box experience)
# TRUNCATION_RECOVERY=true

# ===========================================
# TOOL RESULT GUARD (oversized tool outputs)
# ===========================================

# Guard oversized tool_result payloads (logs/crash dumps/schemas) before forwarding
# to Kiro API. Prevents vague 400 "Improperly formed request" failures.
#
# Behavior:
# - Oversized ACTIVE tool output (latest tool_result): converted to tool error for model.
# - Oversized HISTORICAL tool output (old history): omitted automatically to recover stuck sessions.
#
# This guard only applies to tool results, not normal user prompts.
# Default: true (recommended to avoid Improperly formed request errors)
# Set false for stricter transparent-proxy behavior
# TOOL_RESULT_GUARD_ENABLED=true

# Max chars allowed for a single tool_result block.
# Default: 50000
# TOOL_RESULT_MAX_CHARS=50000

# Max aggregate chars across all tool_result blocks in one request.
# Default: 200000
# TOOL_RESULT_TOTAL_MAX_CHARS=200000

# Guard oversized tool call arguments (function.arguments / tool_use.input)
# Default: true (recommended to avoid Improperly formed request errors)
# Set false for stricter transparent-proxy behavior
# TOOL_CALL_ARGS_GUARD_ENABLED=true

# Max chars allowed for one tool call arguments payload
# Default: 50000
# TOOL_CALL_ARGS_MAX_CHARS=50000

# ===========================================
# QUEUED ANNOUNCE GUARD (OpenClaw busy queue)
# ===========================================

# Compact oversized "Queued announce messages while agent was busy" blocks.
# These system notices may include full subagent reports and can trigger
# vague upstream 400 "Improperly formed request" errors when too large.
#
# Only queued-announce blocks are compacted. Regular user prompts are untouched.
# Default: true
# QUEUED_ANNOUNCE_GUARD_ENABLED=true

# Max chars allowed for one queued-announce text block before compaction.
# Default: 12000
# QUEUED_ANNOUNCE_MAX_CHARS=12000

# Head/tail preview chars kept after compaction.
# Defaults: 6000 / 4000
# QUEUED_ANNOUNCE_HEAD_CHARS=6000
# QUEUED_ANNOUNCE_TAIL_CHARS=4000

# ===========================================
# MIDDLEWARE PIPELINE
# ===========================================

# Tool Pairing Validator: fixes orphaned tool_use/tool_result blocks.
# Default: true (recommended to avoid Improperly formed request errors)
# Set false for stricter transparent-proxy behavior
# TOOL_PAIRING_VALIDATOR_ENABLED=true

# Message Structure Validator: fixes role alternation, empty content, first-message role.
# Default: true (recommended to avoid Improperly formed request errors)
# Set false for stricter transparent-proxy behavior
# MESSAGE_STRUCTURE_VALIDATOR_ENABLED=true

# Reactive Retry: on 400 "Improperly formed request", auto-sanitize and retry once.
# Default: true
# REACTIVE_RETRY_ENABLED=true

# Maximum retry attempts on 400 errors before giving up.
# Default: 1
# REACTIVE_RETRY_MAX_ATTEMPTS=1

# Max serialized Kiro request payload size in BYTES.
# Reverse-engineered upstream behavior (issue #73 comments): failures can start
# around ~615KB. Default keeps safety headroom below that boundary.
# Default: 590000
# KIRO_MAX_PAYLOAD_BYTES=590000
# Legacy alias (deprecated, interpreted as bytes):
# KIRO_MAX_PAYLOAD_CHARS=590000

# Optional hard cap on converted Kiro history entries.
# Default: 0 (disabled; trim only by payload size)
# KIRO_MAX_HISTORY_ENTRIES=0

# Skip upstream Authorization (for direct proxy upstreams that handle auth themselves)
# Default: false
# SKIP_AUTH=false

# Required acknowledgement when SKIP_AUTH=true.
# Prevents accidental startup with upstream Authorization disabled.
# SKIP_AUTH_ACKNOWLEDGED=false

# ===========================================
# LOGGING
# ===========================================

# Log level: TRACE, DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO (recommended for production)
# Set to DEBUG for detailed troubleshooting
# LOG_LEVEL="INFO"

# ===========================================
# DEBUG (for development only)
# ===========================================

# Debug logging mode:
# - off: disabled (default)
# - errors: save logs only for failed requests (4xx, 5xx) - recommended for troubleshooting
# - all: save logs for every request (overwrites on each request)
# DEBUG_MODE=off

# Directory for debug log files
# DEBUG_DIR="debug_logs"
